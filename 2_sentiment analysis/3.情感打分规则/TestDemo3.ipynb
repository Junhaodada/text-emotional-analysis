{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import sys\r\n",
    "import gzip\r\n",
    "from collections import defaultdict\r\n",
    "from itertools import product\r\n",
    "import jieba\r\n",
    "import csv\r\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "class Struct(object):\r\n",
    "    def __init__(self, word, sentiment, pos,value, class_value):\r\n",
    "        self.word = word\r\n",
    "        self.sentiment = sentiment\r\n",
    "        self.pos = pos\r\n",
    "        self.value = value\r\n",
    "        self.class_value = class_value\r\n",
    "\r\n",
    "class Result(object):\r\n",
    "    def __init__(self,score, score_words,not_word, degree_word ):\r\n",
    "        self.score = score\r\n",
    "        self.score_words = score_words\r\n",
    "        self.not_word = not_word\r\n",
    "        self.degree_word = degree_word\r\n",
    "\r\n",
    "class Score(object):\r\n",
    "        # 七个情感大类对应的小类简称: 尊敬\r\n",
    "        score_class = {'乐':['PA','PE'],\r\n",
    "                       '好':['PD','PH', 'PG','PB','PK'],\r\n",
    "                       '怒':['NA' ],\r\n",
    "                       '哀':['NB','NJ','NH', 'PF'],\r\n",
    "                       '惧':['NI', 'NC', 'NG'],\r\n",
    "                       '恶':['NE', 'ND', 'NN','NK','NL'],\r\n",
    "                       '惊':['PC']\r\n",
    "                       }\r\n",
    "        # 大连理工大学 -> ICTPOS 3.0\r\n",
    "        POS_MAP = {\r\n",
    "            'noun': 'n',\r\n",
    "            'verb': 'v',\r\n",
    "            'adj': 'a',\r\n",
    "            'adv': 'd',\r\n",
    "            'nw': 'al',  # 网络用语\r\n",
    "            'idiom': 'al',\r\n",
    "            'prep': 'p',\r\n",
    "        }\r\n",
    "\r\n",
    "        # 否定词\r\n",
    "        NOT_DICT = set(['不','不是','不大', '没', '无', '非', '莫', '弗', '毋',\r\n",
    "                        '勿', '未', '否', '别', '無', '休'])\r\n",
    "\r\n",
    "        def __init__(self, sentiment_dict_path, degree_dict_path, stop_dict_path ):\r\n",
    "            self.sentiment_struct,self.sentiment_dict = self.load_sentiment_dict(sentiment_dict_path)\r\n",
    "            self.degree_dict = self.load_degree_dict(degree_dict_path)\r\n",
    "            self.stop_words = self.load_stop_words(stop_dict_path)\r\n",
    "\r\n",
    "        def load_stop_words(self, stop_dict_path):\r\n",
    "            stop_words = [w for w in open(stop_dict_path).readlines()]\r\n",
    "            #print (stop_words[:100])\r\n",
    "            return stop_words\r\n",
    "\r\n",
    "        def remove_stopword(self, words):\r\n",
    "            words = [w for w in words if w not in self.stop_words]\r\n",
    "            return words\r\n",
    "\r\n",
    "        def load_degree_dict(self, dict_path):\r\n",
    "            \"\"\"读取程度副词词典\r\n",
    "            Args:\r\n",
    "                dict_path: 程度副词词典路径. 格式为 word\\tdegree\r\n",
    "                           所有的词可以分为6个级别，分别对应极其, 很, 较, 稍, 欠, 超\r\n",
    "           Returns:\r\n",
    "                返回 dict = {word: degree}\r\n",
    "            \"\"\"\r\n",
    "            degree_dict = {}\r\n",
    "            with open(dict_path, 'r', encoding='UTF-8') as f:\r\n",
    "                for line in f:\r\n",
    "                    line = line.strip()\r\n",
    "                    word, degree = line.split('\\t')\r\n",
    "                    degree = float(degree)\r\n",
    "                    degree_dict[word] = degree\r\n",
    "            return degree_dict\r\n",
    "\r\n",
    "        def load_sentiment_dict(self, dict_path):\r\n",
    "            \"\"\"读取情感词词典\r\n",
    "            Args:\r\n",
    "                dict_path: 情感词词典路径. 格式请看 README.md\r\n",
    "            Returns:\r\n",
    "                返回 dict = {(word, postag): 极性}\r\n",
    "            \"\"\"\r\n",
    "            sentiment_dict = {}\r\n",
    "            sentiment_struct = []\r\n",
    "\r\n",
    "            with open(dict_path, 'r', encoding='UTF-8') as f:\r\n",
    "            #with gzip.open(dict_path) as f:\r\n",
    "                for index, line in enumerate(f):\r\n",
    "                    if index == 0:  # title,即第一行的标题\r\n",
    "                        continue\r\n",
    "                    items = line.split('\\t')\r\n",
    "                    word = items[0]\r\n",
    "                    pos = items[1]\r\n",
    "                    sentiment=items[4]\r\n",
    "                    intensity = items[5]  # 1, 3, 5, 7, 9五档, 9表示强度最大, 1为强度最小.\r\n",
    "                    polar = items[6]      # 极性\r\n",
    "                    \r\n",
    "                    # 将词性转为 ICTPOS 词性体系\r\n",
    "                    pos = self.__class__.POS_MAP[pos]\r\n",
    "                    intensity = int(intensity)\r\n",
    "                    polar = int(polar)\r\n",
    "\r\n",
    "                    # 转换情感倾向的表现形式, 负数为消极, 0 为中性, 正数为积极\r\n",
    "                    # 数值绝对值大小表示极性的强度 // 分成3类，极性：褒(+1)、中(0)、贬(-1)； 强度为权重值\r\n",
    "                    value = None\r\n",
    "                    if polar == 0:            # neutral\r\n",
    "                        value = 0\r\n",
    "                    elif polar == 1:          # positive\r\n",
    "                        value = intensity\r\n",
    "                    elif polar == 2:          # negtive\r\n",
    "                        value = -1 * intensity\r\n",
    "                    else:  # invalid\r\n",
    "                        continue\r\n",
    "\r\n",
    "                    #key = (word, pos, sentiment )\r\n",
    "                    key = word\r\n",
    "                    sentiment_dict[key] = value\r\n",
    "\r\n",
    "                    #找对应的大类\r\n",
    "                    for item in self.score_class.items():\r\n",
    "                        key = item[0]\r\n",
    "                        values = item[1]\r\n",
    "                        #print(key)\r\n",
    "                        #print(value)\r\n",
    "                        for x in values:\r\n",
    "                            if (sentiment==x):\r\n",
    "                                class_value = key # 如果values中包含，则获取key\r\n",
    "                    sentiment_struct.append(Struct(word, sentiment, pos,value, class_value))\r\n",
    "            return  sentiment_struct, sentiment_dict\r\n",
    "\r\n",
    "        def findword(self, text): #查找文本中包含哪些情感词\r\n",
    "            word_list = []\r\n",
    "            for item in self.sentiment_struct:\r\n",
    "                if item.word in text:\r\n",
    "                    word_list.append(item)\r\n",
    "            return word_list\r\n",
    "\r\n",
    "        def classify_words(self, words):\r\n",
    "            # 这3个键是词的序号(索引)\r\n",
    "            \r\n",
    "            sen_word = {}                 \r\n",
    "            not_word = {}\r\n",
    "            degree_word = {}\r\n",
    "            # 找到对应的sent, not, degree;      words 是分词后的列表\r\n",
    "            for index, word in enumerate(words):\r\n",
    "                if word in self.sentiment_dict and word not in self.__class__.NOT_DICT and word not in self.degree_dict:\r\n",
    "                    sen_word[index] = self.sentiment_dict[word]\r\n",
    "                elif word in self.__class__.NOT_DICT and word not in self.degree_dict:\r\n",
    "                    not_word[index] = -1\r\n",
    "                elif word in self.degree_dict:\r\n",
    "                    degree_word[index] = self.degree_dict[word]\r\n",
    "            return sen_word, not_word, degree_word\r\n",
    "\r\n",
    "\r\n",
    "        def get2score_position(self, words):\r\n",
    "            sen_word, not_word, degree_word =  self.classify_words(words)   # 是字典\r\n",
    "\r\n",
    "            score = 0\r\n",
    "            start = 0\r\n",
    "            # 存所有情感词、否定词、程度副词的位置(索引、序号)的列表\r\n",
    "            sen_locs = sen_word.keys()\r\n",
    "            not_locs = not_word.keys()\r\n",
    "            degree_locs = degree_word.keys()\r\n",
    "            senloc = -1\r\n",
    "            # 遍历句子中所有的单词words，i为单词的绝对位置\r\n",
    "            for i in range(0, len(words)):\r\n",
    "                if i in sen_locs:\r\n",
    "                    W = 1  # 情感词间权重重置\r\n",
    "                    not_locs_index = 0\r\n",
    "                    degree_locs_index = 0\r\n",
    "\r\n",
    "                    # senloc为情感词位置列表的序号,之前的sen_locs是情感词再分词后列表中的位置序号\r\n",
    "                    senloc += 1\r\n",
    "                    #score += W * float(sen_word[i])\r\n",
    "                    if (senloc==0): # 第一个情感词,前面是否有否定词，程度词\r\n",
    "                        start = 0\r\n",
    "                    elif senloc < len(sen_locs):  # 和前面一个情感词之间，是否有否定词,程度词\r\n",
    "                        # j为绝对位置\r\n",
    "                        start = previous_sen_locs\r\n",
    "\r\n",
    "                    for j in range(start,i): # 词间的相对位置\r\n",
    "                        # 如果有否定词\r\n",
    "                        if j in not_locs:\r\n",
    "                            W *= -1\r\n",
    "                            not_locs_index=j\r\n",
    "                        # 如果有程度副词\r\n",
    "                        elif j in degree_locs:\r\n",
    "                            W *= degree_word[j]\r\n",
    "                            degree_locs_index=j\r\n",
    "\r\n",
    "                        # 判断否定词和程度词的位置：1）否定词在前，程度词减半(加上正值)；不是很   2）否定词在后，程度增强（不变），很不是\r\n",
    "                    if ((not_locs_index>0) and (degree_locs_index>0 )):\r\n",
    "                        if (not_locs_index < degree_locs_index ):\r\n",
    "                            degree_reduce = (float(degree_word[degree_locs_index]/2))\r\n",
    "                            W +=degree_reduce\r\n",
    "                            #print (W)\r\n",
    "                    score += W * float(sen_word[i])  # 直接添加该情感词分数\r\n",
    "                    #print(score)\r\n",
    "                    previous_sen_locs = i\r\n",
    "            return score\r\n",
    "\r\n",
    "        #感觉get2score用处不是很大\r\n",
    "        def get2score(self, text):\r\n",
    "            word_list = self.findword(text)  ##查找文本中包含哪些正负情感词，然后分别分别累计它们的数值\r\n",
    "            pos_score = 0\r\n",
    "            pos_word = []\r\n",
    "            neg_score = 0\r\n",
    "            neg_word=[]\r\n",
    "            for word in word_list:\r\n",
    "                if (word.value>0):\r\n",
    "                    pos_score = pos_score + word.value\r\n",
    "                    pos_word.append(word.word)\r\n",
    "                else:\r\n",
    "                    neg_score = neg_score+word.value\r\n",
    "                    neg_word.append(word.word)\r\n",
    "            print (\"pos_score=%d; neg_score=%d\" %(pos_score, neg_score))\r\n",
    "            #print('pos_word',pos_word)\r\n",
    "            #print('neg_word',neg_word)\r\n",
    "\r\n",
    "        def getscore(self, text):\r\n",
    "            word_list = self.findword(text)  ##查找文本中包含哪些情感词\r\n",
    "            # 增加程度副词+否定词\r\n",
    "            not_w = 1\r\n",
    "            not_word = []\r\n",
    "            for notword in self.__class__.NOT_DICT:  # 否定词\r\n",
    "                if notword in text:\r\n",
    "                    not_w = not_w * -1\r\n",
    "                    not_word.append(notword)\r\n",
    "            degree_word = []\r\n",
    "            for degreeword in self.degree_dict.keys():\r\n",
    "                if degreeword in text:\r\n",
    "                    degree = self.degree_dict[degreeword]\r\n",
    "                    #polar = polar + degree if polar > 0 else polar - degree\r\n",
    "                    degree_word.append(degreeword)\r\n",
    "            # 7大类找对应感情大类的词语，分别统计分数= 词极性*词权重\r\n",
    "            result = []\r\n",
    "            for key in self.score_class.keys(): #区分7大类\r\n",
    "                score = 0\r\n",
    "                score_words = []\r\n",
    "                for word in word_list:\r\n",
    "                    \r\n",
    "                    if (key == word.class_value):\r\n",
    "                        score = score + word.value\r\n",
    "                        score_words.append(word.word)\r\n",
    "                if score > 0:\r\n",
    "                    score = score + degree\r\n",
    "                elif score<0:\r\n",
    "                    score = score - degree  # 看分数>0，程度更强； 分数<0,程度减弱？\r\n",
    "                score = score * not_w\r\n",
    "\r\n",
    "                x = '{}_score={}; word={}; nor_word={}; degree_word={};'.format(key, score, score_words,not_word, degree_word)\r\n",
    "                print (x)\r\n",
    "                result.append(x)\r\n",
    "                #key + '_score=%d; word=%s; nor_word=%s; degree_word=%s;'% (score, score_words,not_word, degree_word))\r\n",
    "            return result\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "if __name__ == '__main__':\r\n",
    "    sentiment_dict_path = \"sentiment_words_chinese.tsv\" \r\n",
    "    degree_dict_path = \"degree_dict.txt\"\r\n",
    "    stop_dict_path = \"stop_words.txt\"\r\n",
    "\r\n",
    "    #文件读取\r\n",
    "    f = open('庆余年220.csv',encoding='utf8')\r\n",
    "    data = pd.read_csv(f)\r\n",
    "\r\n",
    "    #文件写入\r\n",
    "    c = open(\"Result.csv\", \"a+\", newline='', encoding='gb18030')\r\n",
    "    writer = csv.writer(c)\r\n",
    "    writer.writerow([\"no\",\"review\",\"score\"])\r\n",
    "\r\n",
    "    #分句功能 否定词程度词位置判断\r\n",
    "    score = Score(sentiment_dict_path, degree_dict_path, stop_dict_path)\r\n",
    "\r\n",
    "    n = 1\r\n",
    "    for temp in data['review']:\r\n",
    "        tlist = []\r\n",
    "        words = [x for x in jieba.cut(temp)] #分词\r\n",
    "        #print(words)     \r\n",
    "        words_ = score.remove_stopword(words)\r\n",
    "        print(words_)\r\n",
    "        \r\n",
    "        #分词->情感词间是否有否定词/程度词+前后顺序->分数累加\r\n",
    "        result = score.get2score_position(words_)  \r\n",
    "        print(result)\r\n",
    "        \r\n",
    "        tlist.append(str(n))\r\n",
    "        tlist.append(words)\r\n",
    "        tlist.append(str(result))\r\n",
    "        writer.writerow(tlist)\r\n",
    "        n = n + 1\r\n",
    "\r\n",
    "        #句子-> 整句判断否定词/程度词 -> 分正负词\r\n",
    "        #score.get2score(temp) \r\n",
    "        #score.getscore(text)\r\n",
    "    c.close()\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "UnicodeDecodeError",
     "evalue": "'gbk' codec can't decode byte 0x80 in position 2511: illegal multibyte sequence",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-86972424eef6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;31m#分句功能 否定词程度词位置判断\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mScore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentiment_dict_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdegree_dict_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstop_dict_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-5e45129dd86d>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, sentiment_dict_path, degree_dict_path, stop_dict_path)\u001b[0m\n\u001b[0;32m     42\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentiment_struct\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentiment_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_sentiment_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentiment_dict_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdegree_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_degree_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdegree_dict_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_stop_words\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstop_dict_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mload_stop_words\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstop_dict_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-5e45129dd86d>\u001b[0m in \u001b[0;36mload_stop_words\u001b[1;34m(self, stop_dict_path)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mload_stop_words\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstop_dict_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m             \u001b[0mstop_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mw\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstop_dict_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m             \u001b[1;31m#print (stop_words[:100])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'gbk' codec can't decode byte 0x80 in position 2511: illegal multibyte sequence"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "interpreter": {
   "hash": "4905652b14e4b7eb92899b78ac499a22c488804455b27940a322fd82aaf71031"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}